# ===========================================
# Hollon-AI Environment Configuration
# ===========================================

# Node Environment
NODE_ENV=development

# ===========================================
# Database (PostgreSQL with pgvector)
# ===========================================
# Database connection settings
DB_HOST=localhost
DB_PORT=5432
DB_NAME=hollon
DB_USER=hollon
DB_PASSWORD=your_secure_password_here

# Full connection URL (alternative to individual settings)
DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}

# Database schema (namespace for tables)
# Default: hollon (development), hollon_test (test environment)
DB_SCHEMA=hollon

# Connection pool configuration
# Maximum number of clients in the pool (default: 10)
DB_POOL_SIZE=10

# Maximum time (ms) a client can be idle before being closed (default: 30000)
DB_IDLE_TIMEOUT_MS=30000

# Maximum time (ms) to wait for a connection from the pool (default: 10000)
DB_CONNECTION_TIMEOUT_MS=10000

# Maximum lifetime (ms) of a connection in the pool (default: 1800000 = 30 minutes)
DB_MAX_LIFETIME_MS=1800000

# pgvector-specific settings
# Enable pgvector extension (should be true for vector search functionality)
PGVECTOR_ENABLED=true

# Default HNSW index parameters for vector similarity search
# m: Maximum number of connections per layer (4-64, default: 16)
# Higher values improve recall but increase memory usage and build time
PGVECTOR_HNSW_M=16

# ef_construction: Size of dynamic candidate list during index construction (4-1000, default: 64)
# Higher values create better quality indexes but slower build times
PGVECTOR_HNSW_EF_CONSTRUCTION=64

# ef_search: Size of dynamic candidate list during search (1-1000, default: 40)
# Higher values improve recall but increase query time
# This can be set per-query, but this is the default
PGVECTOR_HNSW_EF_SEARCH=40

# IVFFlat index parameters (alternative to HNSW for smaller datasets)
# Number of inverted lists (clusters) for IVFFlat index
# Good starting point: sqrt(total_rows), e.g., 100 for 10K rows, 1000 for 1M rows
PGVECTOR_IVFFLAT_LISTS=100

# Number of probes (lists to search) during IVFFlat queries (1-lists, default: 1)
# Higher values improve recall but increase query time
PGVECTOR_IVFFLAT_PROBES=10

# ===========================================
# pgvector Extension Configuration
# ===========================================
# Note: The pgvector extension is automatically enabled via database migration
# No additional environment variables are required for basic pgvector functionality
# The Docker image (pgvector/pgvector:pg16) includes pgvector pre-installed
#
# PostgreSQL Performance Tuning for pgvector (optional, for production):
# These settings can be configured via Docker command arguments or postgresql.conf
#
# Recommended settings for production (16GB RAM):
# - shared_buffers=4GB           # 25% of RAM for buffer cache
# - work_mem=256MB               # Per-operation memory for sorting/hashing
# - maintenance_work_mem=2GB     # Memory for index builds (HNSW/IVFFlat)
# - max_parallel_workers_per_gather=4  # Parallel query workers
# - max_parallel_maintenance_workers=4 # Parallel index build workers
# - hnsw.ef_search=40            # HNSW index search quality (10-1000)
#
# Docker command example:
# command: ['postgres', '-c', 'shared_buffers=1GB', '-c', 'work_mem=128MB']
#
# See docs/pgvector-best-practices.md for detailed tuning guidance

# ===========================================
# Server Configuration
# ===========================================
SERVER_PORT=3001
SERVER_HOST=0.0.0.0

# ===========================================
# Brain Provider - Claude Code
# ===========================================
# Path to Claude Code CLI (if not in PATH)
CLAUDE_CODE_PATH=claude

# Default timeout for brain execution (ms)
BRAIN_TIMEOUT_MS=300000

# ===========================================
# Brain Provider - Anthropic API (optional)
# ===========================================
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ===========================================
# Brain Provider - OpenAI API (for embeddings)
# ===========================================
OPENAI_API_KEY=your_openai_api_key_here

# ===========================================
# Vector Search Configuration
# ===========================================
# Enable/disable vector search functionality
VECTOR_SEARCH_ENABLED=true

# Embedding provider configuration
VECTOR_EMBEDDING_PROVIDER=openai
VECTOR_EMBEDDING_MODEL=text-embedding-3-small
VECTOR_EMBEDDING_DIMENSIONS=1536
VECTOR_EMBEDDING_API_KEY=  # Optional: uses OPENAI_API_KEY by default for OpenAI provider
VECTOR_EMBEDDING_BATCH_SIZE=100
VECTOR_EMBEDDING_MAX_RETRIES=3
VECTOR_EMBEDDING_TIMEOUT_MS=30000

# Search configuration
VECTOR_SEARCH_DEFAULT_METRIC=cosine
VECTOR_SEARCH_DEFAULT_MIN_SIMILARITY=0.7
VECTOR_SEARCH_DEFAULT_LIMIT=10
VECTOR_SEARCH_MAX_LIMIT=100
VECTOR_SEARCH_INCLUDE_SCORES_BY_DEFAULT=true

# Index configuration
VECTOR_INDEX_NAME=vector_embeddings
VECTOR_INDEX_AUTO_CREATE=true
VECTOR_INDEX_LISTS=100
VECTOR_INDEX_PROBES=10

# Performance configuration
VECTOR_PERFORMANCE_ENABLE_CACHE=true
VECTOR_PERFORMANCE_CACHE_TTL_SECONDS=3600
VECTOR_PERFORMANCE_POOL_SIZE=10

# ===========================================
# Cost Limits (in cents)
# ===========================================
DEFAULT_DAILY_COST_LIMIT_CENTS=10000
DEFAULT_MONTHLY_COST_LIMIT_CENTS=100000
COST_ALERT_THRESHOLD_PERCENT=80

# ===========================================
# Logging
# ===========================================
LOG_LEVEL=debug
LOG_FORMAT=pretty

# ===========================================
# Security
# ===========================================
# JWT Secret for API authentication (Phase 5)
JWT_SECRET=your_jwt_secret_here

# Encryption key for credentials (32 bytes hex)
ENCRYPTION_KEY=your_32_byte_hex_encryption_key_here
